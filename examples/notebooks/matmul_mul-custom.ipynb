{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_mlir\n",
    "import numpy\n",
    "\n",
    "from air.backend import linalg_on_tensors as backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = [128,128]\n",
    "DTYPE = torch.int32\n",
    "\n",
    "class MMult_Mult(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, a, b, c):\n",
    "        x = torch.mm(b,c)\n",
    "        y = a*x\n",
    "        return y\n",
    "\n",
    "program = MMult_Mult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = torch_mlir.compile(\n",
    "    program,\n",
    "    (torch.ones(SIZE, dtype=DTYPE), torch.ones(SIZE, dtype=DTYPE), torch.ones(SIZE, dtype=DTYPE)),\n",
    "    output_type=torch_mlir.OutputType.LINALG_ON_TENSORS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbackend = backend.LinalgOnTensorsAirBackend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch_mlir.ir\n",
    "\n",
    "import air.mlir.ir\n",
    "import air.mlir.passmanager\n",
    "import air.compiler.aircc.main as aircc\n",
    "\n",
    "def compile(imported_module: torch_mlir.ir.Module):\n",
    "    with air.mlir.ir.Context():\n",
    "        air_module = air.mlir.ir.Module.parse(str(imported_module))\n",
    "        \n",
    "        # bufferize the linalg dialect\n",
    "        pm = air.mlir.passmanager.PassManager.parse(air.compiler.util.LINALG_TENSOR_TO_MEMREF_PIPELINE)\n",
    "        pm.run(air_module)\n",
    "        \n",
    "        # convert linalg dialect to air dialect\n",
    "        #LINALG_MEMREF_TO_AIR_PIPELINE = \",\".join([\n",
    "        #    \"air-linalg-codegen\",\n",
    "        #    \"canonicalize\",\n",
    "        #    \"cse\",\n",
    "        #    \"affine-to-air\",\n",
    "        #    \"canonicalize\",\n",
    "        #    \"cse\"\n",
    "        #])\n",
    "        # CUSTOM: convert linalg dialect to air dialect\n",
    "        LINALG_MEMREF_TO_AIR_PIPELINE = \",\".join([\n",
    "            \"air-linalg-name\",\n",
    "            \"air-linalg-codegen{input-filter=linalg.matmul1 herd-size=8,2 l1-tile-size=16,64,32}\",\n",
    "            \"air-linalg-codegen{input-filter=linalg.generic2 herd-size=8,1 l1-tile-size=16,128,32}\",\n",
    "            \"air-rm-linalg-name\",\n",
    "            \"canonicalize\",\n",
    "            \"cse\",\n",
    "            \"air-par-to-herd\",\n",
    "            \"air-copy-to-dma\",\n",
    "            \"canonicalize\",\n",
    "            \"cse\"\n",
    "        ])\n",
    "        \n",
    "        pm = air.mlir.passmanager.PassManager.parse(LINALG_MEMREF_TO_AIR_PIPELINE)\n",
    "        pm.run(air_module)\n",
    "        \n",
    "        # print the air dialect mlir\n",
    "        print(air_module)\n",
    "        \n",
    "        # run aircc to build the herds\n",
    "        # the loader expects the output to be called 'torch.mlir.so'\n",
    "        aircc.run(air_module,['--shared', '-o', 'torch.mlir.so', '--sysroot=/', '-row-offset=3', '-col-offset=20', 'torch.mlir'])\n",
    "        \n",
    "        # generate a torch-mlir refbackend interface to the AIR control program so\n",
    "        # that we can reuse the refbackend's jit and object loader on the cpu.\n",
    "        with open('air_project/refback.torch.mlir') as f:\n",
    "            return_module = torch_mlir.ir.Module.parse(f.read(),imported_module.context)\n",
    "        return airbackend.refbackend.compile(return_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#map0 = affine_map<()[s0] -> (s0 * 16)>\n",
      "#map1 = affine_map<()[s0] -> (s0 * 64)>\n",
      "#map2 = affine_map<(d0, d1) -> (d0, d1)>\n",
      "module attributes {torch.debug_module_name = \"MMult_Mult\"} {\n",
      "  func.func @forward(%arg0: memref<128x128xi32>, %arg1: memref<128x128xi32>, %arg2: memref<128x128xi32>) -> memref<128x128xi32> {\n",
      "    %c2 = arith.constant 2 : index\n",
      "    %c1 = arith.constant 1 : index\n",
      "    %c8 = arith.constant 8 : index\n",
      "    %c0_i32 = arith.constant 0 : i32\n",
      "    %0 = memref.alloc() {alignment = 128 : i64} : memref<128x128xi32>\n",
      "    linalg.fill ins(%c0_i32 : i32) outs(%0 : memref<128x128xi32>)\n",
      "    %1 = memref.alloc() {alignment = 128 : i64} : memref<128x128xi32>\n",
      "    memref.copy %0, %1 : memref<128x128xi32> to memref<128x128xi32>\n",
      "    air.herd @herd_0  tile (%arg3, %arg4) in (%arg5=%c8, %arg6=%c2) args(%arg7=%arg1, %arg8=%arg2, %arg9=%1) : memref<128x128xi32>, memref<128x128xi32>, memref<128x128xi32> {\n",
      "      %c64 = arith.constant 64 : index\n",
      "      %c1_0 = arith.constant 1 : index\n",
      "      %c16 = arith.constant 16 : index\n",
      "      %c0 = arith.constant 0 : index\n",
      "      %c128 = arith.constant 128 : index\n",
      "      %c32 = arith.constant 32 : index\n",
      "      %3 = affine.apply #map0()[%arg3]\n",
      "      %4 = affine.apply #map1()[%arg4]\n",
      "      scf.for %arg10 = %c0 to %c128 step %c32 {\n",
      "        %5 = memref.alloc() : memref<16x32xi32, 2>\n",
      "        %6 = memref.alloc() : memref<32x64xi32, 2>\n",
      "        %7 = memref.alloc() : memref<16x64xi32, 2>\n",
      "        air.dma_memcpy_nd (%5[] [] [], %arg7[%3, %arg10] [%c16, %c32] [%c128, %c1_0]) {id = 1 : i32} : (memref<16x32xi32, 2>, memref<128x128xi32>)\n",
      "        air.dma_memcpy_nd (%6[] [] [], %arg8[%arg10, %4] [%c32, %c64] [%c128, %c1_0]) {id = 2 : i32} : (memref<32x64xi32, 2>, memref<128x128xi32>)\n",
      "        air.dma_memcpy_nd (%7[] [] [], %arg9[%3, %4] [%c16, %c64] [%c128, %c1_0]) {id = 3 : i32} : (memref<16x64xi32, 2>, memref<128x128xi32>)\n",
      "        linalg.matmul ins(%5, %6 : memref<16x32xi32, 2>, memref<32x64xi32, 2>) outs(%7 : memref<16x64xi32, 2>)\n",
      "        air.dma_memcpy_nd (%arg9[%3, %4] [%c16, %c64] [%c128, %c1_0], %7[] [] []) {id = 4 : i32} : (memref<128x128xi32>, memref<16x64xi32, 2>)\n",
      "        memref.dealloc %5 : memref<16x32xi32, 2>\n",
      "        memref.dealloc %6 : memref<32x64xi32, 2>\n",
      "        memref.dealloc %7 : memref<16x64xi32, 2>\n",
      "      }\n",
      "      air.herd_terminator\n",
      "    }\n",
      "    %2 = memref.alloc() {alignment = 128 : i64} : memref<128x128xi32>\n",
      "    air.herd @herd_1  tile (%arg3, %arg4) in (%arg5=%c8, %arg6=%c1) args(%arg7=%arg0, %arg8=%1, %arg9=%2) : memref<128x128xi32>, memref<128x128xi32>, memref<128x128xi32> {\n",
      "      %c1_0 = arith.constant 1 : index\n",
      "      %c128 = arith.constant 128 : index\n",
      "      %c16 = arith.constant 16 : index\n",
      "      %c0 = arith.constant 0 : index\n",
      "      %3 = affine.apply #map0()[%arg3]\n",
      "      %4 = memref.alloc() : memref<16x128xi32, 2>\n",
      "      %5 = memref.alloc() : memref<16x128xi32, 2>\n",
      "      %6 = memref.alloc() : memref<16x128xi32, 2>\n",
      "      air.dma_memcpy_nd (%4[] [] [], %arg7[%3, %c0] [%c16, %c128] [%c128, %c1_0]) {id = 5 : i32} : (memref<16x128xi32, 2>, memref<128x128xi32>)\n",
      "      air.dma_memcpy_nd (%5[] [] [], %arg8[%3, %c0] [%c16, %c128] [%c128, %c1_0]) {id = 6 : i32} : (memref<16x128xi32, 2>, memref<128x128xi32>)\n",
      "      air.dma_memcpy_nd (%6[] [] [], %arg9[%3, %c0] [%c16, %c128] [%c128, %c1_0]) {id = 7 : i32} : (memref<16x128xi32, 2>, memref<128x128xi32>)\n",
      "      linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%4, %5 : memref<16x128xi32, 2>, memref<16x128xi32, 2>) outs(%6 : memref<16x128xi32, 2>) {\n",
      "      ^bb0(%arg10: i32, %arg11: i32, %arg12: i32):\n",
      "        %7 = arith.muli %arg10, %arg11 : i32\n",
      "        linalg.yield %7 : i32\n",
      "      }\n",
      "      air.dma_memcpy_nd (%arg9[%3, %c0] [%c16, %c128] [%c128, %c1_0], %6[] [] []) {id = 8 : i32} : (memref<128x128xi32>, memref<16x128xi32, 2>)\n",
      "      memref.dealloc %4 : memref<16x128xi32, 2>\n",
      "      memref.dealloc %5 : memref<16x128xi32, 2>\n",
      "      memref.dealloc %6 : memref<16x128xi32, 2>\n",
      "      air.herd_terminator\n",
      "    }\n",
      "    return %2 : memref<128x128xi32>\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compiled = compile(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_module = airbackend.load(compiled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "tensor([[32, 32, 78,  ..., 51, 17, 98],\n",
      "        [54, 59, 11,  ..., 34, 58,  5],\n",
      "        [15, 60, 31,  ...,  9, 45, 61],\n",
      "        ...,\n",
      "        [35, 12, 76,  ..., 23, 69, 97],\n",
      "        [27,  0, 23,  ..., 58, 56, 41],\n",
      "        [99, 17, 11,  ..., 42, 53, 29]], dtype=torch.int32)\n",
      "tensor([[83, 78,  1,  ..., 35, 75, 77],\n",
      "        [92, 21,  2,  ..., 99, 15,  7],\n",
      "        [18, 82, 98,  ..., 61, 68, 35],\n",
      "        ...,\n",
      "        [55, 52, 55,  ..., 69, 72,  0],\n",
      "        [ 4, 23, 49,  ..., 34, 71, 88],\n",
      "        [83, 71, 75,  ..., 98, 76, 19]], dtype=torch.int32)\n",
      "tensor([[75, 28, 30,  ..., 51, 92, 65],\n",
      "        [28,  7, 73,  ..., 20, 73, 61],\n",
      "        [66, 79, 94,  ..., 13, 72, 78],\n",
      "        ...,\n",
      "        [47,  7, 12,  ..., 80, 71, 25],\n",
      "        [28, 16, 85,  ...,  9, 54, 76],\n",
      "        [93, 64, 18,  ..., 53, 19, 54]], dtype=torch.int32)\n",
      "output:\n",
      "tensor([[11425216, 10173472, 22450350,  ..., 15993039,  5420433, 31370094],\n",
      "        [19196784, 18855869,  3056317,  ..., 10782454, 18140776,  1599750],\n",
      "        [ 5276580, 19095180,  8756663,  ...,  2850651, 14965560, 19607840],\n",
      "        ...,\n",
      "        [12360950,  3965832, 23462720,  ...,  7050052, 22167078, 32774069],\n",
      "        [ 9182781,        0,  6218809,  ..., 16772788, 14950600, 12630706],\n",
      "        [38696328,  6438053,  3522530,  ..., 14689668, 18249278, 10775153]],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(100, SIZE, dtype=torch.int32)\n",
    "b = torch.randint(100, SIZE, dtype=torch.int32)\n",
    "c = torch.randint(100, SIZE, dtype=torch.int32)\n",
    "\n",
    "# run the model on the device\n",
    "o = jit_module.forward(a.numpy(),b.numpy(),c.numpy())\n",
    "\n",
    "# print the results\n",
    "d = torch.tensor(o)    \n",
    "print(f\"input:\\n{a}\\n{b}\\n{c}\\noutput:\\n{d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASS!\n"
     ]
    }
   ],
   "source": [
    "# check the results\n",
    "if torch.equal(a*torch.mm(b,c),d):\n",
    "    print(\"PASS!\")\n",
    "else:\n",
    "    print(\"failed.\")"
   ]
  },
  {
    "cell_type": "markdown",
    "id": "3f02dfbd",
    "metadata": {},
    "source": [
      "Copyright (C) 2022, Advanced Micro Devices, Inc. All rights reserved.\n",
      "\n",
      "SPDX-License-Identifier: MIT"
    ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "air-mlir",
   "language": "python",
   "name": "air-mlir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
