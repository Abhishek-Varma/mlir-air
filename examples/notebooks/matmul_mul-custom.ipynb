{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "\n",
    "from torch_mlir.dialects.torch.importer.jit_ir import ClassAnnotator, ModuleBuilder\n",
    "from torch_mlir.dialects.torch.importer.jit_ir.torchscript_annotations import extract_annotations\n",
    "from torch_mlir_e2e_test.torchscript.annotations import annotate_args, export\n",
    "\n",
    "from torch_mlir.passmanager import PassManager\n",
    "from air.backend import linalg_on_tensors as backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = [128,128]\n",
    "\n",
    "class MMult_Mult(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @export\n",
    "    @annotate_args([\n",
    "        None,\n",
    "        (SIZE, torch.int32, True),\n",
    "        (SIZE, torch.int32, True),\n",
    "        (SIZE, torch.int32, True)\n",
    "    ])\n",
    "    def forward(self, a, b, c):\n",
    "        x = torch.mm(b,c)\n",
    "        y = a*x\n",
    "        return y\n",
    "\n",
    "program = MMult_Mult()\n",
    "scripted = torch.jit.script(program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#map = affine_map<(d0, d1) -> (d0, d1)>\n",
      "module attributes {torch.debug_module_name = \"MMult_Mult\"} {\n",
      "  func @forward(%arg0: tensor<128x128xi32>, %arg1: tensor<128x128xi32>, %arg2: tensor<128x128xi32>) -> tensor<?x?xi32> {\n",
      "    %c0_i32 = arith.constant 0 : i32\n",
      "    %0 = linalg.init_tensor [128, 128] : tensor<128x128xi32>\n",
      "    %1 = linalg.fill(%c0_i32, %0) : i32, tensor<128x128xi32> -> tensor<128x128xi32> \n",
      "    %2 = linalg.matmul ins(%arg1, %arg2 : tensor<128x128xi32>, tensor<128x128xi32>) outs(%1 : tensor<128x128xi32>) -> tensor<128x128xi32>\n",
      "    %3 = linalg.generic {indexing_maps = [#map, #map, #map], iterator_types = [\"parallel\", \"parallel\"]} ins(%arg0, %2 : tensor<128x128xi32>, tensor<128x128xi32>) outs(%0 : tensor<128x128xi32>) {\n",
      "    ^bb0(%arg3: i32, %arg4: i32, %arg5: i32):\n",
      "      %5 = arith.muli %arg3, %arg4 : i32\n",
      "      linalg.yield %5 : i32\n",
      "    } -> tensor<128x128xi32>\n",
      "    %4 = tensor.cast %3 : tensor<128x128xi32> to tensor<?x?xi32>\n",
      "    return %4 : tensor<?x?xi32>\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_annotator = ClassAnnotator()\n",
    "extract_annotations(program, scripted, class_annotator)\n",
    "\n",
    "mb = ModuleBuilder()\n",
    "mb.import_module(scripted._c, class_annotator)\n",
    "\n",
    "pm = PassManager.parse('torchscript-module-to-torch-backend-pipeline,torch-backend-to-linalg-on-tensors-backend-pipeline', mb.module.context)\n",
    "pm.run(mb.module)\n",
    "print(mb.module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbackend = backend.LinalgOnTensorsAirBackend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch_mlir.ir\n",
    "\n",
    "import air.mlir.ir\n",
    "import air.mlir.passmanager\n",
    "import air.compiler.aircc.main as aircc\n",
    "\n",
    "def compile(imported_module: torch_mlir.ir.Module):\n",
    "    with air.mlir.ir.Context():\n",
    "        air_module = air.mlir.ir.Module.parse(str(imported_module))\n",
    "        \n",
    "        # bufferize the linalg dialect\n",
    "        pm = air.mlir.passmanager.PassManager.parse(air.compiler.util.LINALG_TENSOR_TO_MEMREF_PIPELINE)\n",
    "        pm.run(air_module)\n",
    "        #print(air_module)\n",
    "        \n",
    "        # convert linalg dialect to air dialect\n",
    "        LINALG_MEMREF_TO_AIR_PIPELINE = \",\".join([\n",
    "            \"air-linalg-codegen\",\n",
    "            \"canonicalize\",\n",
    "            \"cse\",\n",
    "            \"affine-to-air\",\n",
    "            \"canonicalize\",\n",
    "            \"cse\"\n",
    "        ])\n",
    "        pm = air.mlir.passmanager.PassManager.parse(LINALG_MEMREF_TO_AIR_PIPELINE)\n",
    "        pm.run(air_module)\n",
    "        \n",
    "        # print the air dialect mlir\n",
    "        print(air_module)\n",
    "        \n",
    "        # run aircc to build the herds\n",
    "        # the loader expects the output to be called 'torch.mlir.so'\n",
    "        aircc.run(air_module,['--shared', '-o', 'torch.mlir.so', '--sysroot=/', '-row-offset=3', '-col-offset=20', 'torch.mlir'])\n",
    "        \n",
    "        # generate a torch-mlir refbackend interface to the AIR control program so\n",
    "        # that we can reuse the refbackend's jit and object loader on the cpu.\n",
    "        with open('air_project/refback.torch.mlir') as f:\n",
    "            return_module = torch_mlir.ir.Module.parse(f.read(),imported_module.context)\n",
    "        return airbackend.refbackend.compile(return_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#map0 = affine_map<()[s0] -> (s0 * 32)>\n",
      "#map1 = affine_map<()[s0] -> (s0 * 64)>\n",
      "#map2 = affine_map<(d0, d1) -> (d0, d1)>\n",
      "module attributes {torch.debug_module_name = \"MMult_Mult\"} {\n",
      "  func @forward(%arg0: memref<128x128xi32>, %arg1: memref<128x128xi32>, %arg2: memref<128x128xi32>) -> memref<?x?xi32> {\n",
      "    %c2 = arith.constant 2 : index\n",
      "    %c4 = arith.constant 4 : index\n",
      "    %c0_i32 = arith.constant 0 : i32\n",
      "    %0 = memref.alloc() : memref<128x128xi32>\n",
      "    linalg.fill(%c0_i32, %0) : i32, memref<128x128xi32> \n",
      "    %1 = memref.alloc() : memref<128x128xi32>\n",
      "    linalg.copy(%0, %1) : memref<128x128xi32>, memref<128x128xi32> \n",
      "    air.launch_herd tile (%arg3, %arg4) in (%arg5=%c4, %arg6=%c4) args(%arg7=%arg1, %arg8=%arg2, %arg9=%1) : memref<128x128xi32>, memref<128x128xi32>, memref<128x128xi32> attributes {sym_name = \"herd_0\"} {\n",
      "      %c1024 = arith.constant 1024 : index\n",
      "      %c32 = arith.constant 32 : index\n",
      "      %c128 = arith.constant 128 : index\n",
      "      %c0 = arith.constant 0 : index\n",
      "      %4 = affine.apply #map0()[%arg3]\n",
      "      %5 = affine.apply #map0()[%arg4]\n",
      "      scf.for %arg10 = %c0 to %c128 step %c32 {\n",
      "        %6 = memref.alloc() : memref<32x32xi32, 2>\n",
      "        %7 = memref.alloc() : memref<32x32xi32, 2>\n",
      "        %8 = memref.alloc() : memref<32x32xi32, 2>\n",
      "        air.dma_memcpy_2d (%6, %arg7, [%c0, %c0], [%4, %arg10], %c1024, %c128, %c32) {id = 1 : i32} : (memref<32x32xi32, 2>, memref<128x128xi32>, [index, index], [index, index], index, index, index) -> ()\n",
      "        air.dma_memcpy_2d (%7, %arg8, [%c0, %c0], [%arg10, %5], %c1024, %c128, %c32) {id = 2 : i32} : (memref<32x32xi32, 2>, memref<128x128xi32>, [index, index], [index, index], index, index, index) -> ()\n",
      "        air.dma_memcpy_2d (%8, %arg9, [%c0, %c0], [%4, %5], %c1024, %c128, %c32) {id = 3 : i32} : (memref<32x32xi32, 2>, memref<128x128xi32>, [index, index], [index, index], index, index, index) -> ()\n",
      "        linalg.matmul ins(%6, %7 : memref<32x32xi32, 2>, memref<32x32xi32, 2>) outs(%8 : memref<32x32xi32, 2>)\n",
      "        air.dma_memcpy_2d (%arg9, %8, [%4, %5], [%c0, %c0], %c1024, %c128, %c32) {id = 4 : i32} : (memref<128x128xi32>, memref<32x32xi32, 2>, [index, index], [index, index], index, index, index) -> ()\n",
      "        memref.dealloc %6 : memref<32x32xi32, 2>\n",
      "        memref.dealloc %7 : memref<32x32xi32, 2>\n",
      "        memref.dealloc %8 : memref<32x32xi32, 2>\n",
      "      }\n",
      "      air.herd_terminator\n",
      "    }\n",
      "    %2 = memref.alloc() : memref<128x128xi32>\n",
      "    air.launch_herd tile (%arg3, %arg4) in (%arg5=%c2, %arg6=%c2) args(%arg7=%arg0, %arg8=%1, %arg9=%2) : memref<128x128xi32>, memref<128x128xi32>, memref<128x128xi32> attributes {sym_name = \"herd_1\"} {\n",
      "      %c2048 = arith.constant 2048 : index\n",
      "      %c128 = arith.constant 128 : index\n",
      "      %c32 = arith.constant 32 : index\n",
      "      %c64 = arith.constant 64 : index\n",
      "      %c0 = arith.constant 0 : index\n",
      "      %4 = affine.apply #map1()[%arg3]\n",
      "      %5 = affine.apply #map1()[%arg4]\n",
      "      scf.for %arg10 = %c0 to %c64 step %c32 {\n",
      "        %6 = arith.addi %5, %arg10 : index\n",
      "        %7 = memref.alloc() : memref<64x32xi32, 2>\n",
      "        %8 = memref.alloc() : memref<64x32xi32, 2>\n",
      "        %9 = memref.alloc() : memref<64x32xi32, 2>\n",
      "        air.dma_memcpy_2d (%7, %arg7, [%c0, %c0], [%4, %6], %c2048, %c128, %c32) {id = 5 : i32} : (memref<64x32xi32, 2>, memref<128x128xi32>, [index, index], [index, index], index, index, index) -> ()\n",
      "        air.dma_memcpy_2d (%8, %arg8, [%c0, %c0], [%4, %6], %c2048, %c128, %c32) {id = 6 : i32} : (memref<64x32xi32, 2>, memref<128x128xi32>, [index, index], [index, index], index, index, index) -> ()\n",
      "        air.dma_memcpy_2d (%9, %arg9, [%c0, %c0], [%4, %6], %c2048, %c128, %c32) {id = 7 : i32} : (memref<64x32xi32, 2>, memref<128x128xi32>, [index, index], [index, index], index, index, index) -> ()\n",
      "        linalg.generic {indexing_maps = [#map2, #map2, #map2], iterator_types = [\"parallel\", \"parallel\"]} ins(%7, %8 : memref<64x32xi32, 2>, memref<64x32xi32, 2>) outs(%9 : memref<64x32xi32, 2>) {\n",
      "        ^bb0(%arg11: i32, %arg12: i32, %arg13: i32):\n",
      "          %10 = arith.muli %arg11, %arg12 : i32\n",
      "          linalg.yield %10 : i32\n",
      "        }\n",
      "        air.dma_memcpy_2d (%arg9, %9, [%4, %6], [%c0, %c0], %c2048, %c128, %c32) {id = 8 : i32} : (memref<128x128xi32>, memref<64x32xi32, 2>, [index, index], [index, index], index, index, index) -> ()\n",
      "        memref.dealloc %7 : memref<64x32xi32, 2>\n",
      "        memref.dealloc %8 : memref<64x32xi32, 2>\n",
      "        memref.dealloc %9 : memref<64x32xi32, 2>\n",
      "      }\n",
      "      air.herd_terminator\n",
      "    }\n",
      "    %3 = memref.cast %2 : memref<128x128xi32> to memref<?x?xi32>\n",
      "    return %3 : memref<?x?xi32>\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compiled = compile(mb.module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_module = airbackend.load(compiled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "metal: info:      Registered shmem provider linux_shm.\n",
      "metal: info:      Registered shmem provider ion.reserved.\n",
      "metal: info:      Registered shmem provider ion.ion_system_contig_heap.\n",
      "metal: info:      Registered shmem provider ion.ion_system_heap.\n",
      "metal: info:      device xilinx-aiengine in use by driver uio_dmem_genirq\n",
      "metal: warning:   metal_linux_irq_handling: Failed to set scheduler: Unknown error -1.\n",
      "metal: info:      metal_uio_dev_open: No IRQ for device f70a0000.aie-npi.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "tensor([[21, 48, 86,  ..., 93, 28, 79],\n",
      "        [ 2, 66, 76,  ..., 71, 78, 87],\n",
      "        [ 8, 71,  9,  ..., 86, 84, 81],\n",
      "        ...,\n",
      "        [75, 59, 18,  ..., 73, 91, 91],\n",
      "        [47,  1, 19,  ..., 11,  8, 63],\n",
      "        [86, 73,  3,  ..., 36, 75, 99]], dtype=torch.int32)\n",
      "tensor([[16, 21, 59,  ..., 23, 83, 84],\n",
      "        [30, 42, 42,  ..., 97, 27, 25],\n",
      "        [24, 92, 67,  ..., 70, 20, 66],\n",
      "        ...,\n",
      "        [15, 18, 43,  ..., 39,  6, 95],\n",
      "        [64, 88, 63,  ..., 28,  6, 36],\n",
      "        [52,  5, 73,  ..., 33, 75, 86]], dtype=torch.int32)\n",
      "tensor([[ 1, 19, 88,  ..., 28,  8, 16],\n",
      "        [56, 94, 95,  ..., 90, 49, 98],\n",
      "        [93, 95, 48,  ..., 86, 97, 35],\n",
      "        ...,\n",
      "        [12, 27, 20,  ..., 48, 38, 36],\n",
      "        [99, 23, 69,  ..., 60, 60, 15],\n",
      "        [47, 91, 71,  ..., 57, 11, 29]], dtype=torch.int32)\n",
      "output:\n",
      "tensor([[ 6003564, 14551056, 24231876,  ..., 27490893,  8669500, 23371597],\n",
      "        [  582832, 21115446, 23704932,  ..., 20622376, 25264200, 26259906],\n",
      "        [ 2669640, 22725751,  2856042,  ..., 26808350, 27856668, 27225720],\n",
      "        ...,\n",
      "        [23080575, 17930454,  5071770,  ..., 21032614, 30281069, 29970213],\n",
      "        [15041222,   336955,  6139071,  ...,  3229644,  2820448, 21499632],\n",
      "        [25289074, 21491711,   846252,  ..., 10298988, 23988975, 30386763]],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(100, SIZE, dtype=torch.int32)\n",
    "b = torch.randint(100, SIZE, dtype=torch.int32)\n",
    "c = torch.randint(100, SIZE, dtype=torch.int32)\n",
    "\n",
    "# run the model on the device\n",
    "o = jit_module.forward(a.numpy(),b.numpy(),c.numpy())\n",
    "\n",
    "# print the results\n",
    "d = torch.tensor(o)    \n",
    "print(f\"input:\\n{a}\\n{b}\\n{c}\\noutput:\\n{d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASS!\n"
     ]
    }
   ],
   "source": [
    "# check the results\n",
    "if torch.equal(a*torch.mm(b,c),d):\n",
    "    print(\"PASS!\")\n",
    "else:\n",
    "    print(\"failed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "air-mlir",
   "language": "python",
   "name": "air-mlir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
